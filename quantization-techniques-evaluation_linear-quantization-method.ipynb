{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16000 images under train\n",
      "Loaded 2000 images under test\n",
      "Classes: \n",
      "['flower', 'sugarcane']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "## DATA LOADER\n",
    "data_dir = './images'\n",
    "TRAIN = 'train'\n",
    "VAL = 'val'\n",
    "TEST = 'test'\n",
    "\n",
    "# Squeezenet Takes 224x224 images as input, so we resize all of them\n",
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        # Data augmentation is a good practice for the train set\n",
    "        # Here, we randomly crop the image to 224x224 and\n",
    "        # randomly flip it horizontally.\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    # VAL: transforms.Compose([\n",
    "    #     transforms.Resize(256),\n",
    "    #     transforms.CenterCrop(224),\n",
    "    #     transforms.ToTensor(),\n",
    "    # ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x),\n",
    "        transform=data_transforms[x]\n",
    "    )\n",
    "    for x in [TRAIN, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=8,\n",
    "        shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in [TRAIN, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, TEST]}\n",
    "\n",
    "for x in [TRAIN, TEST]:\n",
    "    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "\n",
    "print(\"Classes: \")\n",
    "class_names = image_datasets[TRAIN].classes\n",
    "print(image_datasets[TRAIN].classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization classes and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation is based on the code available at https://github.com/aaron-xichen/pytorch-playground. Although the refered repository offers some options for quantizing popular CNN architectures like Squeezenet, VGG, Alexnet and Resnet, a more dedicated code for my application was necessary in my opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "\n",
    "def compute_integral_part(input, overflow_rate):\n",
    "    \"\"\"Calculates the scaling factor (sf) that better represents the input\"\"\"\n",
    "    # transform 'input' into an array of the abs of each elements \n",
    "    abs_value = input.abs().view(-1)\n",
    "    # sort the modulus array in descending order\n",
    "    sorted_value = abs_value.sort(dim=0, descending=True)[0]\n",
    "    # find what index corresponds to the max possibe modulus value, considering the overflow_rate.\n",
    "    # for '0' overflow_rate, the index will be the one of the maximum module of all modules, and \n",
    "    # the biggest modulus (index 0) will be chosen\n",
    "    split_idx = int(overflow_rate * len(sorted_value))\n",
    "    # value at that index\n",
    "    v = sorted_value[split_idx]\n",
    "    #print('v is {}'.format(v))\n",
    "    if isinstance(v, Variable):\n",
    "        v = v.data.cpu().numpy()\n",
    "    # get the minimum ammount of bits required to represent the value chosen and consider it the \n",
    "    # scaling factor. The '1e-12' is there to determine the smallest precision (if 'v' is too small)\n",
    "    sf = math.ceil(math.log2(v+1e-12))\n",
    "    #print('sf is {}'.format(sf))\n",
    "    return sf\n",
    "\n",
    "def linear_quantize(input, sf, bits):\n",
    "    \"\"\"Converts a float value from the real numbers domain to a float in the quantized domain\"\"\"\n",
    "    assert bits >= 1, bits\n",
    "    if bits == 1:\n",
    "        return torch.sign(input) - 1\n",
    "    #print('inside sf is {}'.format(sf))\n",
    "    # calculate the minimum step, considering that the 'sf' bits will quantize in the interval [0,1].\n",
    "    # this is equivalento to compute 1/(2^(sf)),  or 2^(-sf)\n",
    "    delta = math.pow(2.0, -sf)\n",
    "    bound = math.pow(2.0, bits-1)\n",
    "    # calculates min and maximum. For 8 bits, the quantized number will be between [-128,127]. \n",
    "    min_val = - bound\n",
    "    max_val = bound - 1\n",
    "    \n",
    "    # dividing the input by delta and flooring\n",
    "    ## rounded = torch.floor(input / delta + 0.5) # Equivalent to torch.round(input / delta)\n",
    "    rounded = torch.round(input / delta)\n",
    "\n",
    "    clipped_value = torch.clamp(rounded, min_val, max_val) * delta\n",
    "    return clipped_value\n",
    "\n",
    "\n",
    "class LinearQuant(nn.Module):\n",
    "    def __init__(self, name, bits, sf=None, overflow_rate=0.0, counter=10):\n",
    "        super(LinearQuant, self).__init__()\n",
    "        self.name = name\n",
    "        self._counter = counter\n",
    "\n",
    "        self.bits = bits\n",
    "        self.sf = sf\n",
    "        self.overflow_rate = overflow_rate\n",
    "\n",
    "    @property\n",
    "    def counter(self):\n",
    "        return self._counter\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self._counter > 0:\n",
    "            self._counter -= 1\n",
    "            sf_new = self.bits - 1 - compute_integral_part(input, self.overflow_rate)\n",
    "            self.sf = min(self.sf, sf_new) if self.sf is not None else sf_new\n",
    "            return input\n",
    "        else:\n",
    "            output = linear_quantize(input, self.sf, self.bits)\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(sf={}, bits={}, overflow_rate={:.3f}, counter={})'.format(\n",
    "self.__class__.__name__, self.sf, self.bits, self.overflow_rate, self.counter)\n",
    "\n",
    "\n",
    "def duplicate_model_with_quant(model, bits, overflow_rate=0.0, counter=10):\n",
    "    \"\"\"assume that original model has at least a nn.Sequential\"\"\"\n",
    "    if isinstance(model, nn.Sequential):\n",
    "        l = OrderedDict()\n",
    "        for k, v in model._modules.items():\n",
    "            if isinstance(v, (nn.Conv2d, nn.Linear, nn.BatchNorm1d, nn.BatchNorm2d, nn.AvgPool2d)):\n",
    "                l[k] = v\n",
    "#                if type == 'linear':\n",
    "#                    quant_layer = LinearQuant('{}_quant'.format(k), bits=bits, overflow_rate=overflow_rate, counter=counter)\n",
    "#                elif type == 'log':\n",
    "#                    # quant_layer = LogQuant('{}_quant'.format(k), bits=bits, overflow_rate=overflow_rate, counter=counter)\n",
    "#                    quant_layer = NormalQuant('{}_quant'.format(k), bits=bits, quant_func=log_minmax_quantize)\n",
    "#                elif type == 'minmax':\n",
    "#                    quant_layer = NormalQuant('{}_quant'.format(k), bits=bits, quant_func=min_max_quantize)\n",
    "#                else:\n",
    "#                    quant_layer = NormalQuant('{}_quant'.format(k), bits=bits, quant_func=tanh_quantize)\n",
    "                quant_layer = LinearQuant('{}_quant'.format(k), bits=bits, overflow_rate=overflow_rate, counter=counter)\n",
    "                l['{}_{}_quant'.format(k, type)] = quant_layer\n",
    "            else:\n",
    "                l[k] = duplicate_model_with_quant(v, bits, overflow_rate, counter)\n",
    "        m = nn.Sequential(l)\n",
    "        return m\n",
    "    else:\n",
    "        for k, v in model._modules.items():\n",
    "            model._modules[k] = duplicate_model_with_quant(v, bits, overflow_rate, counter)\n",
    "    return model\n",
    "\n",
    "def eval_model(squeezenet, criterion, verbose=False):\n",
    "    since = time.time()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    loss_test = 0\n",
    "    acc_test = 0\n",
    "\n",
    "    test_batches = len(dataloaders[TEST])\n",
    "    if verbose:\n",
    "        print(\"Evaluating model\")\n",
    "        print('-' * 10)\n",
    "\n",
    "    squeezenet.train(False)\n",
    "    squeezenet.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloaders[TEST]):\n",
    "            if verbose:\n",
    "                if i % 10 == 0:\n",
    "                    print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "\n",
    "\n",
    "            inputs, labels = data\n",
    "            if use_gpu:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            else:\n",
    "                inputs, labels = inputs, labels\n",
    "\n",
    "            outputs = squeezenet(inputs)\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss_test += loss.data\n",
    "            acc_test += torch.sum(preds == labels.data).item()\n",
    "\n",
    "            # del inputs, labels, outputs, preds\n",
    "            # torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss = loss_test / dataset_sizes[TEST]\n",
    "    avg_acc = acc_test / dataset_sizes[TEST]\n",
    "\n",
    "    elapsed_time = time.time() - since\n",
    "    if verbose:\n",
    "        print()\n",
    "        print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "        print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n",
    "        print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n",
    "        print('-' * 10)\n",
    "    return avg_acc, avg_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.6000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
      "0\n",
      "v is 5\n",
      "2.321928094887651\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 3)\n",
    "x[0,2] = 1\n",
    "x[0,2] = 3.6\n",
    "abs_values = x.abs().view(-1)\n",
    "sorted_values = abs_values.sort(dim=0, descending=True)[0]\n",
    "print(sorted_values)\n",
    "\n",
    "overflow_rate = 0.0\n",
    "split_idx = int(overflow_rate * len(sorted_values))\n",
    "print(split_idx)\n",
    "\n",
    "v = sorted_values[split_idx]\n",
    "v = 5\n",
    "print(\"v is {}\".format(v))\n",
    "a = math.log2(v+1e-12)\n",
    "print(a)\n",
    "\n",
    "sf = compute_integral_part(x, 0.0)\n",
    "print(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sf is 5\n",
      "post-calculated sf is 2.0\n",
      "delta is 0.25\n",
      "a ([32.]) quantized is [128.]\n",
      "a ([32.]) rounded is [32.]\n"
     ]
    }
   ],
   "source": [
    "bits = 8\n",
    "\n",
    "x = torch.ones(1, 1)\n",
    "x[0,0] = 25\n",
    "\n",
    "sf = compute_integral_part(x, 0.0)\n",
    "print('sf is {}'.format(sf))\n",
    "\n",
    "sf = bits - 1. - sf\n",
    "print('post-calculated sf is {}'.format(sf))\n",
    "\n",
    "delta = math.pow(2.0, -sf)\n",
    "print('delta is {}'.format(delta))\n",
    "\n",
    "a = torch.Tensor(1)\n",
    "a[0] = 32\n",
    "quantized = torch.round(a / delta)\n",
    "print('a ({}) quantized is {}'.format(a.numpy(), quantized.numpy()))\n",
    "rounded = quantized*delta\n",
    "print('a ({}) rounded is {}'.format(a.numpy(), rounded.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark =True\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "#parser = argparse.ArgumentParser(description='PyTorch SVHN Example')\n",
    "# parser.add_argument('--type', default='cifar10', help='|'.join(selector.known_models))\n",
    "# parser.add_argument('--quant_method', default='linear', help='linear|minmax|log|tanh')\n",
    "#parser.add_argument('--batch_size', type=int, default=100, help='input batch size for training (default: 64)')\n",
    "#parser.add_argument('--gpu', default=None, help='index of gpus to use')\n",
    "#parser.add_argument('--ngpu', type=int, default=8, help='number of gpus to use')\n",
    "#parser.add_argument('--seed', type=int, default=117, help='random seed (default: 1)')\n",
    "# parser.add_argument('--model_root', default='~/.torch/models/', help='folder to save the model')\n",
    "# parser.add_argument('--data_root', default='/tmp/public_dataset/pytorch/', help='folder to save the model')\n",
    "# parser.add_argument('--logdir', default='log/default', help='folder to save to the log')\n",
    "\n",
    "#parser.add_argument('--input_size', type=int, default=224, help='input size of image')\n",
    "# parser.add_argument('--n_sample', type=int, default=20, help='number of samples to infer the scaling factor')\n",
    "#parser.add_argument('--param_bits', type=int, default=8, help='bit-width for parameters')\n",
    "#parser.add_argument('--bn_bits', type=int, default=32, help='bit-width for running mean and std')\n",
    "#parser.add_argument('--fwd_bits', type=int, default=8, help='bit-width for layer output')\n",
    "# parser.add_argument('--overflow_rate', type=float, default=0.0, help='overflow rate')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = {}\n",
    "\n",
    "args['batch_size'] = 100\n",
    "args['gpu'] = None\n",
    "args['ngpu'] = 8\n",
    "args['seed'] = 117\n",
    "args['input_size'] = 224\n",
    "#args['param_bits'] = 2\n",
    "#args['bn_bits'] = 2\n",
    "#args['fwd_bits'] = 2\n",
    "args['overflow_rate'] = 0.0\n",
    "\n",
    "#args.gpu = misc.auto_select_gpu(utility_bound=0, num_gpu=args.ngpu, selected_gpus=args.gpu)\n",
    "#args.ngpu = len(args.gpu)\n",
    "#misc.ensure_dir(args.logdir)\n",
    "#args.model_root = misc.expand_user(args.model_root)\n",
    "#args.data_root = misc.expand_user(args.data_root)\n",
    "#args.input_size = 299 if 'inception' in args.type else args.input_size\n",
    "#assert args.quant_method in ['linear', 'minmax', 'log', 'tanh']\n",
    "#print(\"=================FLAGS==================\")\n",
    "#for k, v in args.__dict__.items():\n",
    "#    print('{}: {}'.format(k, v))\n",
    "#print(\"========================================\")\n",
    "\n",
    "#assert torch.cuda.is_available(), 'no cuda'\n",
    "torch.manual_seed(args['seed'])\n",
    "torch.cuda.manual_seed(args['seed'])\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model():\n",
    "    # load model and dataset fetcher\n",
    "    # model_raw, ds_fetcher, is_imagenet = selector.select(args.type, model_root=args.model_root)\n",
    "    #squeezenet1_1 = models.squeezenet1_1()\n",
    "\n",
    "    # importing fixed version of squeezenet class and functions\n",
    "    import squeezenet_fix\n",
    "\n",
    "    squeezenet1_1 = squeezenet_fix.squeezenet1_1()\n",
    "\n",
    "    # Freeze training for all layers\n",
    "    for param in squeezenet1_1.features.parameters():\n",
    "        param.require_grad = False\n",
    "\n",
    "    # Newly created modules have require_grad=True by default\n",
    "    num_features = squeezenet1_1.classifier[1].in_channels\n",
    "    features = list(squeezenet1_1.classifier.children())[:-3] # Remove last 3 layers\n",
    "    features.extend([nn.Conv2d(num_features, 2, kernel_size=1)]) # Add\n",
    "    features.extend([nn.ReLU(inplace=True)]) # Add\n",
    "    features.extend([nn.AdaptiveAvgPool2d(output_size=(1,1))]) # Add our layer with 2 outputs\n",
    "    squeezenet1_1.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "\n",
    "    if use_gpu:\n",
    "        squeezenet1_1.load_state_dict(torch.load('./weights/squeezenet_v1-flower-or-crops.pt'))\n",
    "    else:\n",
    "        squeezenet1_1.load_state_dict(torch.load('./weights/squeezenet_v1-flower-or-crops.pt', map_location='cpu'))\n",
    "    #print(squeezenet1_1)\n",
    "    return squeezenet1_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_state_dict(state_dict, bn_bits, param_bits):\n",
    "    if param_bits < 32:\n",
    "        state_dict_quant = OrderedDict()\n",
    "        sf_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            if 'running' in k:\n",
    "                if bn_bits >=32:\n",
    "                    print(\"Ignoring {}\".format(k))\n",
    "                    state_dict_quant[k] = v\n",
    "                    continue\n",
    "                else:\n",
    "                    bits = bn_bits\n",
    "            else:\n",
    "                bits = param_bits\n",
    "\n",
    "    #        if args.quant_method == 'linear':\n",
    "    #            sf = bits - 1. - quant.compute_integral_part(v, overflow_rate=args.overflow_rate)\n",
    "    #            v_quant  = quant.linear_quantize(v, sf, bits=bits)\n",
    "    #        elif args.quant_method == 'log':\n",
    "    #            v_quant = quant.log_minmax_quantize(v, bits=bits)\n",
    "    #        elif args.quant_method == 'minmax':\n",
    "    #            v_quant = quant.min_max_quantize(v, bits=bits)\n",
    "    #        else:\n",
    "    #            v_quant = quant.tanh_quantize(v, bits=bits)\n",
    "    \n",
    "            # The sf will be used to do the quantization. Subtract 1 for dividind the range by 2\n",
    "            # (2^(-sf) will be calculated after), so half of the quatized range represents positive\n",
    "            # numbers and the other half negative numbers. Subtract the ammount of bits required to\n",
    "            # represent the max abs value of the input to adjust the scale. At the end of the day, \n",
    "            # the operation done through these steps is equivalent to consider that you have \"bits - 1\"\n",
    "            # bits to quantize the maximum modulus of the input array. I don't know why to make such simple\n",
    "            # operation not explicit...\n",
    "            sf = bits - 1. - compute_integral_part(v, overflow_rate=args['overflow_rate'])\n",
    "            #sf = compute_integral_part(v, overflow_rate=args['overflow_rate'])\n",
    "            v_quant  = linear_quantize(v, sf, bits=bits)     \n",
    "            state_dict_quant[k] = v_quant\n",
    "        return state_dict_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "\n",
    "def quantize_model_forward_activation(model, fwd_bits):\n",
    "    # Quantize the forward activaton of parameters on the model\n",
    "    if fwd_bits < 32:\n",
    "        model = duplicate_model_with_quant(model, bits=fwd_bits)\n",
    "        #print(squeezenet1_1)\n",
    "        #val_ds_tmp = ds_fetcher(10, data_root=args.data_root, train=False, input_size=args.input_size)\n",
    "        #misc.eval_model(model_raw, val_ds_tmp, ngpu=1, n_sample=args.n_sample, is_imagenet=is_imagenet)\n",
    "        if use_gpu:\n",
    "            model.cuda() #.cuda() will move everything to the GPU side\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse quantization vs accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the accuracy on the test set over different levels of quantization. With this information, it is possible to choose the most suitable quantization level for the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Tests 6/31"
     ]
    }
   ],
   "source": [
    "bits_list = list(range(1, 32))\n",
    "#bits_list = list(range(8, 9))\n",
    "\n",
    "test_accuracies_list = []\n",
    "test_losses_list = []\n",
    "\n",
    "for idx, bits_item in enumerate(bits_list):\n",
    "    print(\"\\rRunning Tests {}/{}\".format(idx+1, len(bits_list)), end='', flush=True)\n",
    "    # Quantize weights\n",
    "    squeezenet1_1 = create_model()\n",
    "    state_dict = squeezenet1_1.state_dict()\n",
    "    state_dict_quant = quantize_state_dict(state_dict, bits_item, bits_item)\n",
    "    #print(state_dict_quant)\n",
    "    squeezenet1_1.load_state_dict(state_dict_quant)\n",
    "\n",
    "    # Quantize forward activation\n",
    "    squeezenet1_1_quant = quantize_model_forward_activation(squeezenet1_1, bits_item)\n",
    "    #print()\n",
    "    #print(squeezenet1_1_quant)\n",
    "\n",
    "    # evaluate\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    #exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "    avg_acc, avg_loss = eval_model(squeezenet1_1_quant, criterion)\n",
    "    test_accuracies_list.append(avg_acc)\n",
    "    test_losses_list.append(avg_loss)\n",
    "    \n",
    "    #print()\n",
    "    #print(idx)\n",
    "    #print(bits_item)\n",
    "    #print(avg_acc)\n",
    "    #print(test_accuracies_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for plotting\n",
    "t = np.array(bits_list)\n",
    "s = np.array(test_accuracies_list)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, s)\n",
    "plt.plot(t, s, 'C0o', alpha=0.5)\n",
    "\n",
    "ax.set(xlabel='quantization (bits)', ylabel='accuracy',\n",
    "       title='Accuracy curve for different quantization levels')\n",
    "ax.grid()\n",
    "\n",
    "fig.savefig(\"acc_over_bits.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
